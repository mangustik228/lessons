{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é : https://spark.apache.org/docs/latest/api/python/reference/pyspark.html#rdd-apis\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –õ–æ–∫–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞–µ–º –≤ Jupiter\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"Python Spark SQL basic example\")\\\n",
    "    .getOrCreate()\n",
    "    # —Å–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç Spark-—Å–µ—Å—Å–∏–∏, –æ–±—Ä–∞—â–∞—è—Å—å –∫ –æ–±—ä–µ–∫—Ç—É builder, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç —Å–µ—Å—Å–∏—é, —É—á–∏—Ç—ã–≤–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
    "# —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ —Ö–æ—Ç–∏–º –∑–∞–ø—É—Å—Ç–∏—Ç—å Spark –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ\n",
    "# –∑–∞–¥–∞—ë–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞—à–µ–≥–æ Spark-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "# —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞ —Å–µ—Å—Å–∏–∏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5,6,7])\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° RDD(–∞–Ω–≥–ª. resilient distributed dataset) ‚Äî –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, –∏–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è. –¢–∏–ø —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π —Å–æ–±–æ–π –Ω–∞–±–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –ø–æ —É–∑–ª–∞–º –∫–ª–∞—Å—Ç–µ—Ä–∞, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –º–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –í–∞—Ä–∏–∞–Ω—Ç 1\n",
    "rdd2 = spark.sparkContext.emptyRDD()\n",
    " # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –í–∞—Ä–∏–∞–Ω—Ç 2\n",
    "rdd2 = spark.sparkContext.parallelize([])\n",
    " # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏–∑ csv\n",
    "rdd3 = spark.sparkContext.textFile('C:/tmp/files/text01.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Ç–∏—Ü–∏–π\n",
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5, 6, 7])\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repartition(val:int) –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Ç–∏—Ü–∏–π\n",
    "rdd.repartition(5)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoalescedRDD[6] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coalesce() –¢–æ–ª—å–∫–æ —É–º–µ–Ω—å—à–∞–µ—Ç\n",
    "rdd.coalesce(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–∏–ø—ã –æ–ø–µ—Ä–∞—Ü–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5, 6, 7])\n",
    "# map –∏ –≤ –∞—Ñ—Ä–∏–∫–µ map\n",
    "rdd2 = rdd.map(lambda x: x + 2)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h | e | l | l | o |   | w | o | r | l | d | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize('hello world')\n",
    "# –ú–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –Ω–µ—Å–∫–æ–ª—å –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "rdd3 = rdd.flatMap(lambda x: x.split(','))\n",
    "for i in rdd3.collect():\n",
    "    print(i, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 34, 6, 6, 8, 10]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è\n",
    "rdd = spark.sparkContext.parallelize([1,2,34,5,6,6,7,8,9,10])\n",
    "rdd4 = rdd.filter(lambda x: x%2 == 0)\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['world', 'hello']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–º\n",
    "rdd = spark.sparkContext.parallelize(['hello','vs','vasya','world'])\n",
    "rdd2 = spark.sparkContext.parallelize(['jopa','spark', 'hello','world'])\n",
    "intersection = rdd.intersection(rdd2)\n",
    "intersection.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd_reduce.collect() = [('beer', 5), ('vodka', 16), ('milk', 0)]\n",
      "rdd_group.map(lambda x: (x[0], list(x[1]))).collect() = [('beer', [1, 5]), ('vodka', [2, 8]), ('milk', [0])]\n"
     ]
    }
   ],
   "source": [
    "# distinct() - —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "# union() - —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π rdd –∏–∑ –¥–≤—É—Ö –¥—Ä—É–≥–∏—Ö\n",
    "# sortByKey() - —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–ª—é—á—É\n",
    "# sortBy(function) - —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ñ-—Ü–∏–∏\n",
    "# join()\n",
    "# reduceByKey(func) - –∞–Ω–∞–ª–æ–≥ groupby\n",
    "# groupByKey() - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∏—Ä—É–µ–º—ã–π –æ–±—ä–µ–∫—Ç(–ø–æ—Ö–æ–∂ –Ω–∞ reduceByKey)\n",
    "rdd = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        ('beer',1),\n",
    "        ('vodka',2),\n",
    "        ('beer',5),\n",
    "        ('milk',0),\n",
    "        ('vodka',8)\n",
    "    ]\n",
    ")\n",
    "rdd_reduce = rdd.reduceByKey(lambda x, y: x * y)\n",
    "rdd_group = rdd.groupByKey()\n",
    "print(f'{rdd_reduce.collect() = }')\n",
    "print(f'{rdd_group.map(lambda x: (x[0], list(x[1]))).collect() = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ–π—Å—Ç–≤–∏—è (actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|–º–µ—Ç–æ–¥|—á—Ç–æ –¥–µ–ª–∞–µ—Ç|–ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è|\n",
    "|--|--|--|\n",
    "|`collect()`|–Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–±—Ä–∞—Ç—å –≤—Å–µ —á–∞—Å—Ç–∏ RDD|—Å–º.–≤—ã—à–µ|\n",
    "|`count()`|–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–æ—á–µ—Ä–Ω–µ–π RDD.|`count(rdd2)` -> 5|\n",
    "|`take(n)`|–ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π `head()` –≤ –ø–∞–Ω–¥–∞—Å|`rdd.take(2)`|\n",
    "|`countByValue()`|–ú–µ—Ç–æ–¥ –ø–æ—Ö–æ–∂ –Ω–∞ reduceByKey(), –Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è, –∫–æ–≥–¥–∞ RDD —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∑–Ω–∞—á–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å. –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–æ–≥–∏—á–µ–Ω value_counts()–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ pandas.|`rdd.countByValue()`->`[(1,8),(2,3),(3,15)]`|\n",
    "|`countByKey()`|–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –º–µ—Ç–æ–¥—É reduceByKey(), —Ç–∞–∫ –∫–∞–∫ —Å—É–º–º–∏—Ä—É–µ—Ç –ø–æ –∫–ª—é—á—É. –û—Ç–ª–∏—á–∏–µ –≤ —Ç–æ–º, —á—Ç–æ reduceByKey() ‚Äî —ç—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é RDD, –∞ countByKey() ‚Äî —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∞.||\n",
    "|`reduce(function)`|—è–≤–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏. –û–Ω –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –µ—ë –∫–æ –≤—Å–µ–π RDD —Ü–µ–ª–∏–∫–æ–º.|`sc.parallelize([1, 2, 3, 4, 5]).reduce(add)` -> 15|\n",
    "|``|||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca06022eeaaba41f8106b5e7859db2308ae98973a4e7711a4dd80a8bd4150e2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
